{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2024 Semester 1\n",
    "\n",
    "## Assignment 2 IMDB Movie Rating Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python3.12.0 \n",
    "##run on HPC, 24 CPUs; GPU NVIDIA A30\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([  24,  235, 1839,  777,  129]))\n"
     ]
    }
   ],
   "source": [
    "## load the data and split them into attributes and labels \n",
    "data_train = pd.read_csv('project_data/train_dataset.csv')\n",
    "data_test = pd.read_csv('project_data/test_dataset.csv')\n",
    "X_train = data_train.iloc[:,1:-1] ## the id column is removed \n",
    "y_train = data_train.iloc[:,-1]\n",
    "X_test = data_test.iloc[:,1:] ## the id column is removed\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the preprocessed text feature\n",
    "train_title_embedding = np.load('project_data/features_fasttext/train_fasttext_title_embeddings.npy')\n",
    "test_title_embedding = np.load('project_data/features_fasttext/test_fasttext_title_embeddings.npy')\n",
    "\n",
    "train_genres = np.load('project_data/features_doc2vec/train_doc2vec_features_genre.npy')\n",
    "test_genres = np.load('project_data/features_doc2vec/test_doc2vec_features_genre.npy')\n",
    "\n",
    "train_plot_keywords = np.load('project_data/features_doc2vec/train_doc2vec_features_plot_keywords.npy')\n",
    "test_plot_keywords = np.load('project_data/features_doc2vec/test_doc2vec_features_plot_keywords.npy')\n",
    "\n",
    "train_director_name = np.load('project_data/features_countvec/train_countvec_features_director_name.npy')\n",
    "test_director_name = np.load('project_data/features_countvec/test_countvec_features_director_name.npy')\n",
    "\n",
    "train_actor_1_name = np.load('project_data/features_countvec/train_countvec_features_actor_1_name.npy')\n",
    "test_actor_1_name = np.load('project_data/features_countvec/test_countvec_features_actor_1_name.npy')\n",
    "\n",
    "train_actor_2_name = np.load('project_data/features_countvec/train_countvec_features_actor_2_name.npy')\n",
    "test_actor_2_name = np.load('project_data/features_countvec/test_countvec_features_actor_2_name.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the proprecessed text feature actor_3_name is not provided. \n",
    "## Use CountVectorizer, the same method applied to the other actor names to convert them to numeric \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "actor_3_name = vectorizer.fit_transform(pd.concat([X_train['actor_3_name'],X_test['actor_3_name']],ignore_index=True)).toarray()\n",
    "\n",
    "train_actor_3_name = actor_3_name[0:(len(X_train['actor_3_name']))]\n",
    "test_actor_3_name = actor_3_name[(len(X_train['actor_3_name'])):]\n",
    "\n",
    "actor_3_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the proprecessed text feature language, country, and content_rating are not provided\n",
    "## As they are categorial features, one hot encoding is used\n",
    "def one_hot_encode(text):\n",
    "    vector = np.array([1 if (word == text) else 0 for word in vocabulary])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(pd.concat([X_train['language'],X_test['language']],ignore_index=True))\n",
    "train_language = X_train['language'].apply(one_hot_encode)\n",
    "test_language = X_test['language'].apply(one_hot_encode)\n",
    "\n",
    "train_language = np.vstack(train_language).reshape(-1, len(train_language[0]))\n",
    "test_language = np.vstack(test_language).reshape(-1, len(test_language[0]))\n",
    "\n",
    "train_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(pd.concat([X_train['country'],X_test['country']],ignore_index=True))\n",
    "train_country = X_train['country'].apply(one_hot_encode)\n",
    "test_country = X_test['country'].apply(one_hot_encode)\n",
    "\n",
    "train_country = np.vstack(train_country).reshape(-1, len(train_country[0]))\n",
    "test_country = np.vstack(test_country).reshape(-1, len(test_country[0]))\n",
    "\n",
    "train_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(pd.concat([X_train['content_rating'],X_test['content_rating']],ignore_index=True))\n",
    "train_content_rating = X_train['content_rating'].apply(one_hot_encode)\n",
    "test_content_rating = X_test['content_rating'].apply(one_hot_encode)\n",
    "\n",
    "train_content_rating = np.vstack(train_content_rating).reshape(-1, len(train_content_rating[0]))\n",
    "test_content_rating = np.vstack(test_content_rating).reshape(-1, len(test_content_rating[0]))\n",
    "\n",
    "train_content_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Round 1, only including numeric data without standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## there are two kinds of features, numeric features and text features \n",
    "numeric_features = ['num_critic_for_reviews','duration','director_facebook_likes','actor_3_facebook_likes','actor_1_facebook_likes','gross','num_voted_users','cast_total_facebook_likes','facenumber_in_poster','num_user_for_reviews','title_year','actor_2_facebook_likes','movie_facebook_likes','average_degree_centrality']\n",
    "text_features = ['title_embedding','genres','plot_keywords','director_name','actor_1_name','actor_2_name','actor_3_name','language','country','content_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['director_name', 'num_critic_for_reviews', 'duration',\n",
      "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
      "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
      "       'num_voted_users', 'cast_total_facebook_likes', 'actor_3_name',\n",
      "       'facenumber_in_poster', 'plot_keywords', 'num_user_for_reviews',\n",
      "       'language', 'country', 'content_rating', 'title_year',\n",
      "       'actor_2_facebook_likes', 'movie_facebook_likes', 'title_embedding',\n",
      "       'average_degree_centrality'],\n",
      "      dtype='object')\n",
      "Index(['director_name', 'num_critic_for_reviews', 'duration',\n",
      "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
      "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
      "       'num_voted_users', 'cast_total_facebook_likes', 'actor_3_name',\n",
      "       'facenumber_in_poster', 'plot_keywords', 'num_user_for_reviews',\n",
      "       'language', 'country', 'content_rating', 'title_year',\n",
      "       'actor_2_facebook_likes', 'movie_facebook_likes', 'title_embedding',\n",
      "       'average_degree_centrality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### the movie title_embedding is included, dropping the movie title column \n",
    "X_train.drop(columns=['movie_title'], inplace=True)\n",
    "X_test.drop(columns=['movie_title'], inplace=True)\n",
    "print(X_train.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get backup for training and test sets\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### since the preprocessed text features are of high dimensions, consider the numeric features only first \n",
    "X_train = X_train[numeric_features]\n",
    "X_test = X_test[numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>average_degree_centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>847</td>\n",
       "      <td>2000</td>\n",
       "      <td>422783777</td>\n",
       "      <td>644348</td>\n",
       "      <td>6458</td>\n",
       "      <td>0</td>\n",
       "      <td>656</td>\n",
       "      <td>1994</td>\n",
       "      <td>886</td>\n",
       "      <td>17000</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>654</td>\n",
       "      <td>20433940</td>\n",
       "      <td>78883</td>\n",
       "      <td>1876</td>\n",
       "      <td>8</td>\n",
       "      <td>662</td>\n",
       "      <td>2005</td>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>117</td>\n",
       "      <td>234</td>\n",
       "      <td>221</td>\n",
       "      <td>12000</td>\n",
       "      <td>371897</td>\n",
       "      <td>36494</td>\n",
       "      <td>13607</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>2013</td>\n",
       "      <td>1000</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.003002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>957</td>\n",
       "      <td>13782838</td>\n",
       "      <td>258078</td>\n",
       "      <td>1757</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>1982</td>\n",
       "      <td>163</td>\n",
       "      <td>23000</td>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>16000</td>\n",
       "      <td>313837577</td>\n",
       "      <td>1238746</td>\n",
       "      <td>22342</td>\n",
       "      <td>2</td>\n",
       "      <td>5060</td>\n",
       "      <td>2001</td>\n",
       "      <td>5000</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>161</td>\n",
       "      <td>129</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>97</td>\n",
       "      <td>93952276</td>\n",
       "      <td>132048</td>\n",
       "      <td>318</td>\n",
       "      <td>7</td>\n",
       "      <td>203</td>\n",
       "      <td>2009</td>\n",
       "      <td>50</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>393</td>\n",
       "      <td>123</td>\n",
       "      <td>2000</td>\n",
       "      <td>471</td>\n",
       "      <td>26000</td>\n",
       "      <td>26903709</td>\n",
       "      <td>312629</td>\n",
       "      <td>37206</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2013</td>\n",
       "      <td>10000</td>\n",
       "      <td>83000</td>\n",
       "      <td>0.003302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>216</td>\n",
       "      <td>118</td>\n",
       "      <td>473</td>\n",
       "      <td>963</td>\n",
       "      <td>18000</td>\n",
       "      <td>73343413</td>\n",
       "      <td>217480</td>\n",
       "      <td>22517</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "      <td>2009</td>\n",
       "      <td>1000</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.003302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>109</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>1060591</td>\n",
       "      <td>9750</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>41</td>\n",
       "      <td>115</td>\n",
       "      <td>399</td>\n",
       "      <td>83</td>\n",
       "      <td>399</td>\n",
       "      <td>44456509</td>\n",
       "      <td>22105</td>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>2013</td>\n",
       "      <td>89</td>\n",
       "      <td>14000</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3004 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_critic_for_reviews  duration  director_facebook_likes  \\\n",
       "0                        186        73                       28   \n",
       "1                        252        97                        0   \n",
       "2                        232       117                      234   \n",
       "3                        297       109                        0   \n",
       "4                        297       171                        0   \n",
       "...                      ...       ...                      ...   \n",
       "2999                     161       129                       42   \n",
       "3000                     393       123                     2000   \n",
       "3001                     216       118                      473   \n",
       "3002                     109        95                        0   \n",
       "3003                      41       115                      399   \n",
       "\n",
       "      actor_3_facebook_likes  actor_1_facebook_likes      gross  \\\n",
       "0                        847                    2000  422783777   \n",
       "1                        233                     654   20433940   \n",
       "2                        221                   12000     371897   \n",
       "3                        145                     957   13782838   \n",
       "4                        857                   16000  313837577   \n",
       "...                      ...                     ...        ...   \n",
       "2999                      49                      97   93952276   \n",
       "3000                     471                   26000   26903709   \n",
       "3001                     963                   18000   73343413   \n",
       "3002                       0                     227    1060591   \n",
       "3003                      83                     399   44456509   \n",
       "\n",
       "      num_voted_users  cast_total_facebook_likes  facenumber_in_poster  \\\n",
       "0              644348                       6458                     0   \n",
       "1               78883                       1876                     8   \n",
       "2               36494                      13607                     2   \n",
       "3              258078                       1757                     0   \n",
       "4             1238746                      22342                     2   \n",
       "...               ...                        ...                   ...   \n",
       "2999           132048                        318                     7   \n",
       "3000           312629                      37206                     0   \n",
       "3001           217480                      22517                     0   \n",
       "3002             9750                        231                     0   \n",
       "3003            22105                        688                     1   \n",
       "\n",
       "      num_user_for_reviews  title_year  actor_2_facebook_likes  \\\n",
       "0                      656        1994                     886   \n",
       "1                      662        2005                     529   \n",
       "2                      118        2013                    1000   \n",
       "3                      911        1982                     163   \n",
       "4                     5060        2001                    5000   \n",
       "...                    ...         ...                     ...   \n",
       "2999                   203        2009                      50   \n",
       "3000                   475        2013                   10000   \n",
       "3001                   429        2009                    1000   \n",
       "3002                    66        2007                       4   \n",
       "3003                    81        2013                      89   \n",
       "\n",
       "      movie_facebook_likes  average_degree_centrality  \n",
       "0                    17000                   0.001576  \n",
       "1                        0                   0.000675  \n",
       "2                    11000                   0.003002  \n",
       "3                    23000                   0.001726  \n",
       "4                    21000                   0.001876  \n",
       "...                    ...                        ...  \n",
       "2999                 12000                   0.000750  \n",
       "3000                 83000                   0.003302  \n",
       "3001                 21000                   0.003302  \n",
       "3002                     0                   0.000300  \n",
       "3003                 14000                   0.000525  \n",
       "\n",
       "[3004 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>average_degree_centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>14</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>2246000</td>\n",
       "      <td>2302</td>\n",
       "      <td>3384</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>749</td>\n",
       "      <td>47307550</td>\n",
       "      <td>104301</td>\n",
       "      <td>1948</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>2012</td>\n",
       "      <td>463</td>\n",
       "      <td>28000</td>\n",
       "      <td>0.002176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>388</td>\n",
       "      <td>963</td>\n",
       "      <td>37606</td>\n",
       "      <td>31836</td>\n",
       "      <td>2658</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>2009</td>\n",
       "      <td>654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>15000</td>\n",
       "      <td>104054514</td>\n",
       "      <td>200359</td>\n",
       "      <td>16828</td>\n",
       "      <td>0</td>\n",
       "      <td>1009</td>\n",
       "      <td>2002</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "      <td>38</td>\n",
       "      <td>690</td>\n",
       "      <td>801</td>\n",
       "      <td>3447339</td>\n",
       "      <td>29517</td>\n",
       "      <td>2667</td>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "      <td>2013</td>\n",
       "      <td>727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>179</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>766</td>\n",
       "      <td>13000</td>\n",
       "      <td>17096053</td>\n",
       "      <td>134458</td>\n",
       "      <td>15716</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>1998</td>\n",
       "      <td>933</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>393</td>\n",
       "      <td>105</td>\n",
       "      <td>335</td>\n",
       "      <td>911</td>\n",
       "      <td>3000</td>\n",
       "      <td>37516013</td>\n",
       "      <td>128629</td>\n",
       "      <td>8281</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>2012</td>\n",
       "      <td>3000</td>\n",
       "      <td>98000</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>55</td>\n",
       "      <td>117</td>\n",
       "      <td>133</td>\n",
       "      <td>249</td>\n",
       "      <td>687</td>\n",
       "      <td>20966644</td>\n",
       "      <td>29610</td>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1985</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>85</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>3000</td>\n",
       "      <td>47887943</td>\n",
       "      <td>11634</td>\n",
       "      <td>4480</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2003</td>\n",
       "      <td>455</td>\n",
       "      <td>227</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>35</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>624</td>\n",
       "      <td>2000</td>\n",
       "      <td>19539</td>\n",
       "      <td>4182</td>\n",
       "      <td>6227</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>2003</td>\n",
       "      <td>1000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_critic_for_reviews  duration  director_facebook_likes  \\\n",
       "0                        27       118                       14   \n",
       "1                       339       141                        0   \n",
       "2                        78        95                       89   \n",
       "3                       226       117                        0   \n",
       "4                        97       104                       38   \n",
       "..                      ...       ...                      ...   \n",
       "747                     179        93                        0   \n",
       "748                     393       105                      335   \n",
       "749                      55       117                      133   \n",
       "750                      85        72                        0   \n",
       "751                      35        87                        4   \n",
       "\n",
       "     actor_3_facebook_likes  actor_1_facebook_likes      gross  \\\n",
       "0                       400                    2000    2246000   \n",
       "1                       404                     749   47307550   \n",
       "2                       388                     963      37606   \n",
       "3                       818                   15000  104054514   \n",
       "4                       690                     801    3447339   \n",
       "..                      ...                     ...        ...   \n",
       "747                     766                   13000   17096053   \n",
       "748                     911                    3000   37516013   \n",
       "749                     249                     687   20966644   \n",
       "750                     384                    3000   47887943   \n",
       "751                     624                    2000      19539   \n",
       "\n",
       "     num_voted_users  cast_total_facebook_likes  facenumber_in_poster  \\\n",
       "0               2302                       3384                     4   \n",
       "1             104301                       1948                     4   \n",
       "2              31836                       2658                     0   \n",
       "3             200359                      16828                     0   \n",
       "4              29517                       2667                     7   \n",
       "..               ...                        ...                   ...   \n",
       "747           134458                      15716                     2   \n",
       "748           128629                       8281                     0   \n",
       "749            29610                       1665                     0   \n",
       "750            11634                       4480                     0   \n",
       "751             4182                       6227                     1   \n",
       "\n",
       "     num_user_for_reviews  title_year  actor_2_facebook_likes  \\\n",
       "0                      20        2015                     769   \n",
       "1                     269        2012                     463   \n",
       "2                      90        2009                     654   \n",
       "3                    1009        2002                    1000   \n",
       "4                      79        2013                     727   \n",
       "..                    ...         ...                     ...   \n",
       "747                   640        1998                     933   \n",
       "748                   348        2012                    3000   \n",
       "749                    94        1985                     443   \n",
       "750                    58        2003                     455   \n",
       "751                    53        2003                    1000   \n",
       "\n",
       "     movie_facebook_likes  average_degree_centrality  \n",
       "0                       0                   0.000375  \n",
       "1                   28000                   0.002176  \n",
       "2                       0                   0.000900  \n",
       "3                       0                   0.003452  \n",
       "4                       0                   0.000450  \n",
       "..                    ...                        ...  \n",
       "747                  5000                   0.002777  \n",
       "748                 98000                   0.001801  \n",
       "749                     0                   0.001126  \n",
       "750                   227                   0.000825  \n",
       "751                  3000                   0.002401  \n",
       "\n",
       "[752 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train a 0-R model first to set the based line \n",
    "from sklearn.dummy import DummyClassifier\n",
    "R_0 = DummyClassifier(strategy='most_frequent')\n",
    "R_0.fit(X_train,y_train)\n",
    "y_pred_R_0 = R_0.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_R_0}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_OR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.29527296937416775\n"
     ]
    }
   ],
   "source": [
    "## using GNB to predict \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "## perform cross validation\n",
    "cross_val_predict_gnb = cross_val_predict(gnb, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_gnb) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_gnb}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_GNB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.5818908122503329\n"
     ]
    }
   ],
   "source": [
    "## using KNN5\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "cross_val_predict_KNN = cross_val_predict(KNN, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_KNN) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred_KNN = KNN.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_KNN}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_KNN5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.7213715046604527\n"
     ]
    }
   ],
   "source": [
    "## using random forest \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=888,n_jobs=-1)\n",
    "\n",
    "cross_val_predict_rf = cross_val_predict(rf_regressor, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_rf) == y_train.values)/len(y_train.values)) \n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "y_pred_rf = np.round(y_pred_rf) ## avoid some predictions not being integer \n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_rf}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_voted_users</td>\n",
       "      <td>0.358911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gross</td>\n",
       "      <td>0.101240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.079245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_year</td>\n",
       "      <td>0.065952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_user_for_reviews</td>\n",
       "      <td>0.062958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actor_3_facebook_likes</td>\n",
       "      <td>0.055618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_critic_for_reviews</td>\n",
       "      <td>0.044510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>director_facebook_likes</td>\n",
       "      <td>0.042663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cast_total_facebook_likes</td>\n",
       "      <td>0.042459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>actor_2_facebook_likes</td>\n",
       "      <td>0.037495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>average_degree_centrality</td>\n",
       "      <td>0.033164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>movie_facebook_likes</td>\n",
       "      <td>0.031951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor_1_facebook_likes</td>\n",
       "      <td>0.028729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facenumber_in_poster</td>\n",
       "      <td>0.015108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     features  importance\n",
       "6             num_voted_users    0.358911\n",
       "5                       gross    0.101240\n",
       "1                    duration    0.079245\n",
       "10                 title_year    0.065952\n",
       "9        num_user_for_reviews    0.062958\n",
       "3      actor_3_facebook_likes    0.055618\n",
       "0      num_critic_for_reviews    0.044510\n",
       "2     director_facebook_likes    0.042663\n",
       "7   cast_total_facebook_likes    0.042459\n",
       "11     actor_2_facebook_likes    0.037495\n",
       "13  average_degree_centrality    0.033164\n",
       "12       movie_facebook_likes    0.031951\n",
       "4      actor_1_facebook_likes    0.028729\n",
       "8        facenumber_in_poster    0.015108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance = pd.DataFrame({'features': X_train[numeric_features].columns,\n",
    "        'importance': rf_regressor.feature_importances_})\n",
    "df_importance.sort_values(by='importance', ascending=False, inplace=True)\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 18:50:00.014421: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-15 18:50:00.080336: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## using Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Concatenate, Input, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 18:50:04.578061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22467 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:65:00.0, compute capability: 8.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715763005.870627   60820 service.cc:145] XLA service 0x2b3574014230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1715763005.870672   60820 service.cc:153]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0\n",
      "2024-05-15 18:50:05.899405: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-15 18:50:06.022717: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1715763007.464618   60820 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6121661129568107\n"
     ]
    }
   ],
   "source": [
    "### cross validation for Neuron network \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=666)\n",
    "\n",
    "accuracy = []\n",
    "# Iterate over K folds\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # Split data into training and test sets\n",
    "    #all_fold_indices.append(test_index) \n",
    "    X_train_temp, X_test_temp = X_train.values[train_index], X_train.values[test_index]\n",
    "    y_train_temp, y_test_temp = y_train.values[train_index], y_train.values[test_index]\n",
    "    y_train_categorical_temp = to_categorical(y_train_temp)\n",
    "    \n",
    "    ## set the model\n",
    "    \n",
    "    np.random.seed(888)\n",
    "    tf.random.set_seed(888)\n",
    "    random.seed(888)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],))) # input layer\n",
    "    model.add(Dense(512, activation='relu')) # hiden layer with 512 neurons\n",
    "    model.add(Dropout(0.2)) # drop out some neurons avoiding overfitting\n",
    "    model.add(Dense(1, activation='relu')) # pseudo regression-like output layer\n",
    "    model.add(Dense(5, activation='softmax'))  # output layer with 5 neurons for 5 classes using softmax activation\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_temp, y_train_categorical_temp, epochs=50, verbose=0)\n",
    "\n",
    "    # Generate predictions on the \"test set\"\n",
    "    predictions = np.argmax(model.predict(X_test_temp, verbose=0),axis=1)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy + [sum(predictions == y_test_temp)/len(y_test_temp)]\n",
    "    \n",
    "print('cross-val acc:',np.mean(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6067 - loss: 5804.0991\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6236 - loss: 1.5093\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.6236 - loss: 1.4399\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6236 - loss: 1.3792\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6236 - loss: 1.3262\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6236 - loss: 1.2800\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.6236 - loss: 1.2401\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.6236 - loss: 1.2059\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6236 - loss: 1.1766\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.6236 - loss: 1.1517\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.6236 - loss: 1.1306\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.6236 - loss: 1.1129\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6236 - loss: 1.0979\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.6236 - loss: 1.0854\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.6236 - loss: 1.0748\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.6236 - loss: 1.0659\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.6236 - loss: 1.0584\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.6236 - loss: 1.0521\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6236 - loss: 1.0467\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.6236 - loss: 1.0421\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.6236 - loss: 1.0381\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.6236 - loss: 1.0347\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6236 - loss: 1.0318\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.6236 - loss: 1.0292\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.6236 - loss: 1.0270\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.6236 - loss: 1.0250\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.6236 - loss: 1.0233\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6236 - loss: 1.0217\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.6236 - loss: 1.0203\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6236 - loss: 1.0191\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.6236 - loss: 1.0180\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6236 - loss: 1.0170\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.6236 - loss: 1.0161\n",
      "Epoch 34/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.6236 - loss: 1.0153\n",
      "Epoch 35/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.6236 - loss: 1.0145\n",
      "Epoch 36/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.6236 - loss: 1.0139\n",
      "Epoch 37/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.6236 - loss: 1.0132\n",
      "Epoch 38/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.6236 - loss: 1.0127\n",
      "Epoch 39/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.6236 - loss: 1.0122\n",
      "Epoch 40/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6236 - loss: 1.0117\n",
      "Epoch 41/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6236 - loss: 1.0112\n",
      "Epoch 42/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6236 - loss: 1.0108\n",
      "Epoch 43/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.6236 - loss: 1.0105\n",
      "Epoch 44/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6236 - loss: 1.0101\n",
      "Epoch 45/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.6236 - loss: 1.0098\n",
      "Epoch 46/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.6236 - loss: 1.0095\n",
      "Epoch 47/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6236 - loss: 1.0092\n",
      "Epoch 48/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6236 - loss: 1.0090\n",
      "Epoch 49/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6236 - loss: 1.0087\n",
      "Epoch 50/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.6236 - loss: 1.0085\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train.values)\n",
    "np.random.seed(888)\n",
    "tf.random.set_seed(888)\n",
    "random.seed(888)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.values.shape[1],)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train.values, y_train_categorical, epochs=50)\n",
    "#model_nn = model\n",
    "y_pred_nn = model.predict(X_test.values)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_nn}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_NN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Round 2, only including numeric data with standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16819334, -1.69245592, -0.25111333, ..., -0.23801553,\n",
       "         0.40441232, -0.13749659],\n",
       "       [ 0.71259343, -0.59691369, -0.26047711, ..., -0.31478479,\n",
       "        -0.45198568, -0.8986283 ],\n",
       "       [ 0.5476237 ,  0.31603816, -0.18222263, ..., -0.21350097,\n",
       "         0.10215421,  1.06762748],\n",
       "       ...,\n",
       "       [ 0.41564792,  0.36168575, -0.10229605, ..., -0.21350097,\n",
       "         0.60591774,  1.32133777],\n",
       "       [-0.46694011, -0.68820888, -0.26047711, ..., -0.42768078,\n",
       "        -0.45198568, -1.21576594],\n",
       "       [-1.02783718,  0.22474297, -0.12704319, ..., -0.40940238,\n",
       "         0.25328326, -1.02548302]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.14331598,  0.36168575, -0.25579522, ..., -0.2631752 ,\n",
       "        -0.45198568, -1.15233858],\n",
       "       [ 1.43021174,  1.41158038, -0.26047711, ..., -0.32897743,\n",
       "         0.95855221,  0.36992398],\n",
       "       [-0.72264318, -0.68820888, -0.23071365, ..., -0.2879048 ,\n",
       "        -0.45198568, -0.70834537],\n",
       "       ...,\n",
       "       [-0.91235837,  0.31603816, -0.21599914, ..., -0.33327823,\n",
       "        -0.45198568, -0.51806244],\n",
       "       [-0.66490378, -1.73810351, -0.26047711, ..., -0.33069775,\n",
       "        -0.44055025, -0.77177273],\n",
       "       [-1.07732809, -1.05338962, -0.25913943, ..., -0.21350097,\n",
       "        -0.30085662,  0.56020691]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.2789613848202397\n"
     ]
    }
   ],
   "source": [
    "## using GNB to predict \n",
    "gnb = GaussianNB()\n",
    "\n",
    "cross_val_predict_gnb = cross_val_predict(gnb, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_gnb) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_gnb}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_GNB_scale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6264980026631158\n"
     ]
    }
   ],
   "source": [
    "## using KNN5\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "cross_val_predict_KNN = cross_val_predict(KNN, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_KNN) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred_KNN = KNN.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_KNN}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_KNN5_scale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.7217043941411452\n"
     ]
    }
   ],
   "source": [
    "## using random forest \n",
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=888,n_jobs=-1)\n",
    "\n",
    "cross_val_predict_rf = cross_val_predict(rf_regressor, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_rf) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "y_pred_rf = np.round(y_pred_rf) ## avoid some predictions not being integer \n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_rf}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_rf_scale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_voted_users</td>\n",
       "      <td>0.358911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gross</td>\n",
       "      <td>0.101240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.079245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_year</td>\n",
       "      <td>0.065952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_user_for_reviews</td>\n",
       "      <td>0.062958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actor_3_facebook_likes</td>\n",
       "      <td>0.055618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_critic_for_reviews</td>\n",
       "      <td>0.044510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>director_facebook_likes</td>\n",
       "      <td>0.042663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cast_total_facebook_likes</td>\n",
       "      <td>0.042459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>actor_2_facebook_likes</td>\n",
       "      <td>0.037495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>average_degree_centrality</td>\n",
       "      <td>0.033164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>movie_facebook_likes</td>\n",
       "      <td>0.031951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor_1_facebook_likes</td>\n",
       "      <td>0.028729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facenumber_in_poster</td>\n",
       "      <td>0.015108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     features  importance\n",
       "6             num_voted_users    0.358911\n",
       "5                       gross    0.101240\n",
       "1                    duration    0.079245\n",
       "10                 title_year    0.065952\n",
       "9        num_user_for_reviews    0.062958\n",
       "3      actor_3_facebook_likes    0.055618\n",
       "0      num_critic_for_reviews    0.044510\n",
       "2     director_facebook_likes    0.042663\n",
       "7   cast_total_facebook_likes    0.042459\n",
       "11     actor_2_facebook_likes    0.037495\n",
       "13  average_degree_centrality    0.033164\n",
       "12       movie_facebook_likes    0.031951\n",
       "4      actor_1_facebook_likes    0.028729\n",
       "8        facenumber_in_poster    0.015108"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance = pd.DataFrame({'features': X_train_copy[numeric_features].columns,\n",
    "        'importance': rf_regressor.feature_importances_})\n",
    "df_importance.sort_values(by='importance', ascending=False, inplace=True)\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6937264673311184\n"
     ]
    }
   ],
   "source": [
    "### cross validation\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=666)\n",
    "\n",
    "accuracy = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    \n",
    "    ## split the training set \n",
    "    \n",
    "    X_train_temp, X_test_temp = X_train[train_index], X_train[test_index]\n",
    "    y_train_temp, y_test_temp = y_train[train_index], y_train[test_index]\n",
    "    y_train_categorical_temp = to_categorical(y_train_temp)\n",
    "    \n",
    "    ## set the model\n",
    "    \n",
    "    np.random.seed(888)\n",
    "    tf.random.set_seed(888)\n",
    "    random.seed(888)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],))) # input layer\n",
    "    model.add(Dense(512, activation='relu')) # hiden layer with 512 neurons\n",
    "    model.add(Dropout(0.2)) # drop out some neurons avoiding overfitting\n",
    "    model.add(Dense(1, activation='relu')) # pseudo regression-like output layer\n",
    "    model.add(Dense(5, activation='softmax'))  # output layer with 5 neurons for 5 classes using softmax activation\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_temp, y_train_categorical_temp, epochs=50, verbose=0)\n",
    "\n",
    "    # Generate predictions on the \"test set\"\n",
    "    predictions = np.argmax(model.predict(X_test_temp, verbose=0),axis=1)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy + [sum(predictions == y_test_temp)/len(y_test_temp)]\n",
    "    \n",
    "print('cross-val acc:',np.mean(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6238 - loss: 1.3931\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.6582 - loss: 1.1573\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.6631 - loss: 1.0703\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.6709 - loss: 1.0160\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.6760 - loss: 0.9754\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.6750 - loss: 0.9390\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.6845 - loss: 0.9221\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.6833 - loss: 0.9032\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.6866 - loss: 0.8879\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6894 - loss: 0.8801\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.6873 - loss: 0.8715\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.6921 - loss: 0.8607\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.6950 - loss: 0.8596\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.6952 - loss: 0.8504\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6932 - loss: 0.8516\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.6940 - loss: 0.8468\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.6953 - loss: 0.8396\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.6959 - loss: 0.8369\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.7009 - loss: 0.8307\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7036 - loss: 0.8250\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.6990 - loss: 0.8255\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.6962 - loss: 0.8214\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7068 - loss: 0.8114\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6972 - loss: 0.8167\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7023 - loss: 0.8126\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7092 - loss: 0.8029\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7052 - loss: 0.8045\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7061 - loss: 0.7994\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7021 - loss: 0.7981\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7047 - loss: 0.7982\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7082 - loss: 0.7917\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7129 - loss: 0.7883\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7117 - loss: 0.7867\n",
      "Epoch 34/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.7117 - loss: 0.7853\n",
      "Epoch 35/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7051 - loss: 0.7834\n",
      "Epoch 36/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.7131 - loss: 0.7776\n",
      "Epoch 37/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7151 - loss: 0.7764\n",
      "Epoch 38/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7115 - loss: 0.7747\n",
      "Epoch 39/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7172 - loss: 0.7745\n",
      "Epoch 40/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7115 - loss: 0.7767\n",
      "Epoch 41/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7119 - loss: 0.7642\n",
      "Epoch 42/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.7134 - loss: 0.7676\n",
      "Epoch 43/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7143 - loss: 0.7636\n",
      "Epoch 44/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.7149 - loss: 0.7637\n",
      "Epoch 45/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7186 - loss: 0.7604\n",
      "Epoch 46/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7150 - loss: 0.7660\n",
      "Epoch 47/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7225 - loss: 0.7570\n",
      "Epoch 48/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7245 - loss: 0.7576\n",
      "Epoch 49/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7167 - loss: 0.7564\n",
      "Epoch 50/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7262 - loss: 0.7490\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "np.random.seed(888)\n",
    "tf.random.set_seed(888)\n",
    "random.seed(888)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, epochs=50)\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_nn}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_NN_scale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_copy.copy()\n",
    "X_test = X_test_copy.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Round 3, including text features and with standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_embedding\n",
      "training set  PC1: min: -0.019224618 max 0.034412663\n",
      "training set  PC2: min: -0.0094109345 max 0.009616705\n",
      "test set  PC1: min: -0.017691333 max 0.026750533\n",
      "test set  PC2: min: -0.008997158 max 0.008628372\n",
      "genres\n",
      "training set  PC1: min: -0.018505985 max 0.019414203\n",
      "training set  PC2: min: -0.016693272 max 0.017568637\n",
      "test set  PC1: min: -0.018449714 max 0.019391654\n",
      "test set  PC2: min: -0.016694069 max 0.017549878\n",
      "plot_keywords\n",
      "training set  PC1: min: -0.010268084 max 0.011913228\n",
      "training set  PC2: min: -0.011101094 max 0.012587468\n",
      "test set  PC1: min: -0.009904355 max 0.010138965\n",
      "test set  PC2: min: -0.011012451 max 0.011121323\n",
      "director_name\n",
      "training set  PC1: min: -0.16650595824865771 max 1.033929846009026\n",
      "training set  PC2: min: -0.21443343010341392 max 1.0445152899239785\n",
      "test set  PC1: min: -0.1665059582486577 max 1.033929846009026\n",
      "test set  PC2: min: -0.1804064436199437 max 1.0445152899239785\n",
      "actor_1_name\n",
      "training set  PC1: min: -0.07722631356924756 max 1.5791612035779417\n",
      "training set  PC2: min: -0.07926944016825396 max 1.1588598818335758\n",
      "test set  PC1: min: -0.07722631356924756 max 1.5791612035779417\n",
      "test set  PC2: min: -0.07926944016825396 max 1.1588598818335758\n",
      "actor_2_name\n",
      "training set  PC1: min: -0.08338013710791724 max 1.0725213638789646\n",
      "training set  PC2: min: -0.5801984294552145 max 1.1539984031200505\n",
      "test set  PC1: min: -0.08338013710791724 max 1.0348689441002898\n",
      "test set  PC2: min: -0.5801984294552145 max 1.1539984031200505\n",
      "actor_3_name\n",
      "training set  PC1: min: -0.0751072964986508 max 1.1613658811579393\n",
      "training set  PC2: min: -0.4653619918125061 max 1.058276227623718\n",
      "test set  PC1: min: -0.06838696261548023 max 1.1613658811579393\n",
      "test set  PC2: min: -0.4653619918125061 max 0.9376851069273786\n",
      "language\n",
      "training set  PC1: min: -0.04399180859982776 max 1.1382043457085147\n",
      "training set  PC2: min: -0.5547680170124081 max 0.7556579380470383\n",
      "test set  PC1: min: -0.04399180859982776 max 1.1382043457085147\n",
      "test set  PC2: min: -0.5547680170124081 max 0.7556579380470383\n",
      "country\n",
      "training set  PC1: min: -0.22411718615896598 max 1.1131168369585283\n",
      "training set  PC2: min: -0.4800855816190521 max 0.6978260634295725\n",
      "test set  PC1: min: -0.22411718615896598 max 1.1131168369585283\n",
      "test set  PC2: min: -0.4800855816190521 max 0.6978260634295725\n",
      "content_rating\n",
      "training set  PC1: min: -0.6470472285611034 max 0.7632109901374124\n",
      "training set  PC2: min: -0.2635443717586793 max 1.0091106378256183\n",
      "test set  PC1: min: -0.6470472285611002 max 0.7632109901374091\n",
      "test set  PC2: min: -0.26354437175866674 max 1.0091106378256178\n"
     ]
    }
   ],
   "source": [
    "### introduce PCA component to training set\n",
    "nrow_train=X_train.shape[0]\n",
    "for i in text_features:\n",
    "    print(i)\n",
    "    df_temp = pd.concat([pd.DataFrame(globals()['train_'+i]),pd.DataFrame(globals()['test_'+i])], axis=0, ignore_index=True)\n",
    "    pca = PCA(n_components=2)  \n",
    "    pca_temp = pca.fit_transform(df_temp)\n",
    "    df_pca = pd.DataFrame(pca_temp)\n",
    "    X_train.drop(columns=[i], inplace=True)\n",
    "    X_train[i+'_PC1'] = df_pca.iloc[0:nrow_train,0]\n",
    "    X_train[i+'_PC2'] = df_pca.iloc[0:nrow_train,1]\n",
    "    print('training set',' PC1:','min:',np.min(X_train[i+'_PC1']),'max',np.max(X_train[i+'_PC1']))\n",
    "    print('training set',' PC2:','min:',np.min(X_train[i+'_PC2']),'max',np.max(X_train[i+'_PC2']))\n",
    "    X_test.drop(columns=[i], inplace=True)\n",
    "    X_test[i+'_PC1'] = df_pca.iloc[nrow_train:,0].values\n",
    "    X_test[i+'_PC2'] = df_pca.iloc[nrow_train:,1].values\n",
    "    print('test set',' PC1:','min:',np.min(X_test[i+'_PC1']),'max',np.max(X_test[i+'_PC1']))\n",
    "    print('test set',' PC2:','min:',np.min(X_test[i+'_PC2']),'max',np.max(X_test[i+'_PC2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>actor_2_name_PC1</th>\n",
       "      <th>actor_2_name_PC2</th>\n",
       "      <th>actor_3_name_PC1</th>\n",
       "      <th>actor_3_name_PC2</th>\n",
       "      <th>language_PC1</th>\n",
       "      <th>language_PC2</th>\n",
       "      <th>country_PC1</th>\n",
       "      <th>country_PC2</th>\n",
       "      <th>content_rating_PC1</th>\n",
       "      <th>content_rating_PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>847</td>\n",
       "      <td>2000</td>\n",
       "      <td>422783777</td>\n",
       "      <td>644348</td>\n",
       "      <td>6458</td>\n",
       "      <td>0</td>\n",
       "      <td>656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018911</td>\n",
       "      <td>-0.009801</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.245086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>654</td>\n",
       "      <td>20433940</td>\n",
       "      <td>78883</td>\n",
       "      <td>1876</td>\n",
       "      <td>8</td>\n",
       "      <td>662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>-0.011324</td>\n",
       "      <td>-0.017776</td>\n",
       "      <td>-0.006196</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.704948</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>117</td>\n",
       "      <td>234</td>\n",
       "      <td>221</td>\n",
       "      <td>12000</td>\n",
       "      <td>371897</td>\n",
       "      <td>36494</td>\n",
       "      <td>13607</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017017</td>\n",
       "      <td>-0.008776</td>\n",
       "      <td>-0.016929</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>957</td>\n",
       "      <td>13782838</td>\n",
       "      <td>258078</td>\n",
       "      <td>1757</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021173</td>\n",
       "      <td>-0.012834</td>\n",
       "      <td>-0.052814</td>\n",
       "      <td>0.900699</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>16000</td>\n",
       "      <td>313837577</td>\n",
       "      <td>1238746</td>\n",
       "      <td>22342</td>\n",
       "      <td>2</td>\n",
       "      <td>5060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018607</td>\n",
       "      <td>-0.010668</td>\n",
       "      <td>-0.020062</td>\n",
       "      <td>-0.006440</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.660089</td>\n",
       "      <td>0.345869</td>\n",
       "      <td>0.763211</td>\n",
       "      <td>-0.263544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>161</td>\n",
       "      <td>129</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>97</td>\n",
       "      <td>93952276</td>\n",
       "      <td>132048</td>\n",
       "      <td>318</td>\n",
       "      <td>7</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015630</td>\n",
       "      <td>-0.007890</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>0.763211</td>\n",
       "      <td>-0.263544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>393</td>\n",
       "      <td>123</td>\n",
       "      <td>2000</td>\n",
       "      <td>471</td>\n",
       "      <td>26000</td>\n",
       "      <td>26903709</td>\n",
       "      <td>312629</td>\n",
       "      <td>37206</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021192</td>\n",
       "      <td>-0.016594</td>\n",
       "      <td>-0.019386</td>\n",
       "      <td>-0.006127</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>1.113117</td>\n",
       "      <td>-0.480086</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>216</td>\n",
       "      <td>118</td>\n",
       "      <td>473</td>\n",
       "      <td>963</td>\n",
       "      <td>18000</td>\n",
       "      <td>73343413</td>\n",
       "      <td>217480</td>\n",
       "      <td>22517</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017388</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>0.998885</td>\n",
       "      <td>0.131660</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>109</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>1060591</td>\n",
       "      <td>9750</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015405</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>-0.017476</td>\n",
       "      <td>-0.005328</td>\n",
       "      <td>0.911420</td>\n",
       "      <td>-0.124156</td>\n",
       "      <td>0.749516</td>\n",
       "      <td>0.697826</td>\n",
       "      <td>0.148904</td>\n",
       "      <td>1.009111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>41</td>\n",
       "      <td>115</td>\n",
       "      <td>399</td>\n",
       "      <td>83</td>\n",
       "      <td>399</td>\n",
       "      <td>44456509</td>\n",
       "      <td>22105</td>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016862</td>\n",
       "      <td>-0.008925</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>1.051030</td>\n",
       "      <td>-0.554768</td>\n",
       "      <td>0.655743</td>\n",
       "      <td>0.336442</td>\n",
       "      <td>0.763211</td>\n",
       "      <td>-0.263544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3004 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_critic_for_reviews  duration  director_facebook_likes  \\\n",
       "0                        186        73                       28   \n",
       "1                        252        97                        0   \n",
       "2                        232       117                      234   \n",
       "3                        297       109                        0   \n",
       "4                        297       171                        0   \n",
       "...                      ...       ...                      ...   \n",
       "2999                     161       129                       42   \n",
       "3000                     393       123                     2000   \n",
       "3001                     216       118                      473   \n",
       "3002                     109        95                        0   \n",
       "3003                      41       115                      399   \n",
       "\n",
       "      actor_3_facebook_likes  actor_1_facebook_likes      gross  \\\n",
       "0                        847                    2000  422783777   \n",
       "1                        233                     654   20433940   \n",
       "2                        221                   12000     371897   \n",
       "3                        145                     957   13782838   \n",
       "4                        857                   16000  313837577   \n",
       "...                      ...                     ...        ...   \n",
       "2999                      49                      97   93952276   \n",
       "3000                     471                   26000   26903709   \n",
       "3001                     963                   18000   73343413   \n",
       "3002                       0                     227    1060591   \n",
       "3003                      83                     399   44456509   \n",
       "\n",
       "      num_voted_users  cast_total_facebook_likes  facenumber_in_poster  \\\n",
       "0              644348                       6458                     0   \n",
       "1               78883                       1876                     8   \n",
       "2               36494                      13607                     2   \n",
       "3              258078                       1757                     0   \n",
       "4             1238746                      22342                     2   \n",
       "...               ...                        ...                   ...   \n",
       "2999           132048                        318                     7   \n",
       "3000           312629                      37206                     0   \n",
       "3001           217480                      22517                     0   \n",
       "3002             9750                        231                     0   \n",
       "3003            22105                        688                     1   \n",
       "\n",
       "      num_user_for_reviews  ...  actor_2_name_PC1  actor_2_name_PC2  \\\n",
       "0                      656  ...         -0.018911         -0.009801   \n",
       "1                      662  ...         -0.019053         -0.011324   \n",
       "2                      118  ...         -0.017017         -0.008776   \n",
       "3                      911  ...         -0.021173         -0.012834   \n",
       "4                     5060  ...         -0.018607         -0.010668   \n",
       "...                    ...  ...               ...               ...   \n",
       "2999                   203  ...         -0.015630         -0.007890   \n",
       "3000                   475  ...         -0.021192         -0.016594   \n",
       "3001                   429  ...         -0.017388         -0.009394   \n",
       "3002                    66  ...         -0.015405         -0.007712   \n",
       "3003                    81  ...         -0.016862         -0.008925   \n",
       "\n",
       "      actor_3_name_PC1  actor_3_name_PC2  language_PC1  language_PC2  \\\n",
       "0            -0.016433         -0.004900     -0.043992      0.000986   \n",
       "1            -0.017776         -0.006196     -0.043992      0.000986   \n",
       "2            -0.016929         -0.005098     -0.043992      0.000986   \n",
       "3            -0.052814          0.900699     -0.043992      0.000986   \n",
       "4            -0.020062         -0.006440     -0.043992      0.000986   \n",
       "...                ...               ...           ...           ...   \n",
       "2999         -0.016433         -0.004900     -0.043992      0.000986   \n",
       "3000         -0.019386         -0.006127     -0.043992      0.000986   \n",
       "3001          0.998885          0.131660     -0.043992      0.000986   \n",
       "3002         -0.017476         -0.005328      0.911420     -0.124156   \n",
       "3003         -0.016433         -0.004900      1.051030     -0.554768   \n",
       "\n",
       "      country_PC1  country_PC2  content_rating_PC1  content_rating_PC2  \n",
       "0       -0.224117    -0.022061            0.097988            0.245086  \n",
       "1        0.704948     0.473141           -0.647047           -0.158164  \n",
       "2       -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "3       -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "4        0.660089     0.345869            0.763211           -0.263544  \n",
       "...           ...          ...                 ...                 ...  \n",
       "2999    -0.224117    -0.022061            0.763211           -0.263544  \n",
       "3000     1.113117    -0.480086           -0.647047           -0.158164  \n",
       "3001    -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "3002     0.749516     0.697826            0.148904            1.009111  \n",
       "3003     0.655743     0.336442            0.763211           -0.263544  \n",
       "\n",
       "[3004 rows x 34 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>actor_2_name_PC1</th>\n",
       "      <th>actor_2_name_PC2</th>\n",
       "      <th>actor_3_name_PC1</th>\n",
       "      <th>actor_3_name_PC2</th>\n",
       "      <th>language_PC1</th>\n",
       "      <th>language_PC2</th>\n",
       "      <th>country_PC1</th>\n",
       "      <th>country_PC2</th>\n",
       "      <th>content_rating_PC1</th>\n",
       "      <th>content_rating_PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>14</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>2246000</td>\n",
       "      <td>2302</td>\n",
       "      <td>3384</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015405</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>-0.018475</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>0.148904</td>\n",
       "      <td>1.009111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>749</td>\n",
       "      <td>47307550</td>\n",
       "      <td>104301</td>\n",
       "      <td>1948</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016344</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>-0.020046</td>\n",
       "      <td>-0.006035</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>388</td>\n",
       "      <td>963</td>\n",
       "      <td>37606</td>\n",
       "      <td>31836</td>\n",
       "      <td>2658</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021758</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>-0.018002</td>\n",
       "      <td>-0.005545</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.704948</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>15000</td>\n",
       "      <td>104054514</td>\n",
       "      <td>200359</td>\n",
       "      <td>16828</td>\n",
       "      <td>0</td>\n",
       "      <td>1009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054480</td>\n",
       "      <td>0.602579</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "      <td>38</td>\n",
       "      <td>690</td>\n",
       "      <td>801</td>\n",
       "      <td>3447339</td>\n",
       "      <td>29517</td>\n",
       "      <td>2667</td>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015405</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>-0.031841</td>\n",
       "      <td>-0.012266</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>179</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>766</td>\n",
       "      <td>13000</td>\n",
       "      <td>17096053</td>\n",
       "      <td>134458</td>\n",
       "      <td>15716</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016344</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>-0.005318</td>\n",
       "      <td>-0.013488</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>393</td>\n",
       "      <td>105</td>\n",
       "      <td>335</td>\n",
       "      <td>911</td>\n",
       "      <td>3000</td>\n",
       "      <td>37516013</td>\n",
       "      <td>128629</td>\n",
       "      <td>8281</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018085</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>-0.017500</td>\n",
       "      <td>-0.005353</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>55</td>\n",
       "      <td>117</td>\n",
       "      <td>133</td>\n",
       "      <td>249</td>\n",
       "      <td>687</td>\n",
       "      <td>20966644</td>\n",
       "      <td>29610</td>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017016</td>\n",
       "      <td>-0.008721</td>\n",
       "      <td>-0.017698</td>\n",
       "      <td>-0.005206</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>1.113117</td>\n",
       "      <td>-0.480086</td>\n",
       "      <td>0.093643</td>\n",
       "      <td>0.222252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>85</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>3000</td>\n",
       "      <td>47887943</td>\n",
       "      <td>11634</td>\n",
       "      <td>4480</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017606</td>\n",
       "      <td>-0.018814</td>\n",
       "      <td>-0.023203</td>\n",
       "      <td>-0.007817</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.245086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>35</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>624</td>\n",
       "      <td>2000</td>\n",
       "      <td>19539</td>\n",
       "      <td>4182</td>\n",
       "      <td>6227</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033696</td>\n",
       "      <td>0.210684</td>\n",
       "      <td>-0.021495</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>-0.224117</td>\n",
       "      <td>-0.022061</td>\n",
       "      <td>-0.647047</td>\n",
       "      <td>-0.158164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_critic_for_reviews  duration  director_facebook_likes  \\\n",
       "0                        27       118                       14   \n",
       "1                       339       141                        0   \n",
       "2                        78        95                       89   \n",
       "3                       226       117                        0   \n",
       "4                        97       104                       38   \n",
       "..                      ...       ...                      ...   \n",
       "747                     179        93                        0   \n",
       "748                     393       105                      335   \n",
       "749                      55       117                      133   \n",
       "750                      85        72                        0   \n",
       "751                      35        87                        4   \n",
       "\n",
       "     actor_3_facebook_likes  actor_1_facebook_likes      gross  \\\n",
       "0                       400                    2000    2246000   \n",
       "1                       404                     749   47307550   \n",
       "2                       388                     963      37606   \n",
       "3                       818                   15000  104054514   \n",
       "4                       690                     801    3447339   \n",
       "..                      ...                     ...        ...   \n",
       "747                     766                   13000   17096053   \n",
       "748                     911                    3000   37516013   \n",
       "749                     249                     687   20966644   \n",
       "750                     384                    3000   47887943   \n",
       "751                     624                    2000      19539   \n",
       "\n",
       "     num_voted_users  cast_total_facebook_likes  facenumber_in_poster  \\\n",
       "0               2302                       3384                     4   \n",
       "1             104301                       1948                     4   \n",
       "2              31836                       2658                     0   \n",
       "3             200359                      16828                     0   \n",
       "4              29517                       2667                     7   \n",
       "..               ...                        ...                   ...   \n",
       "747           134458                      15716                     2   \n",
       "748           128629                       8281                     0   \n",
       "749            29610                       1665                     0   \n",
       "750            11634                       4480                     0   \n",
       "751             4182                       6227                     1   \n",
       "\n",
       "     num_user_for_reviews  ...  actor_2_name_PC1  actor_2_name_PC2  \\\n",
       "0                      20  ...         -0.015405         -0.007712   \n",
       "1                     269  ...         -0.016344         -0.008476   \n",
       "2                      90  ...         -0.021758         -0.024972   \n",
       "3                    1009  ...         -0.054480          0.602579   \n",
       "4                      79  ...         -0.015405         -0.007712   \n",
       "..                    ...  ...               ...               ...   \n",
       "747                   640  ...         -0.016344         -0.008476   \n",
       "748                   348  ...         -0.018085         -0.010169   \n",
       "749                    94  ...         -0.017016         -0.008721   \n",
       "750                    58  ...         -0.017606         -0.018814   \n",
       "751                    53  ...         -0.033696          0.210684   \n",
       "\n",
       "     actor_3_name_PC1  actor_3_name_PC2  language_PC1  language_PC2  \\\n",
       "0           -0.018475          0.011968     -0.043992      0.000986   \n",
       "1           -0.020046         -0.006035     -0.043992      0.000986   \n",
       "2           -0.018002         -0.005545     -0.043992      0.000986   \n",
       "3           -0.016433         -0.004900     -0.043992      0.000986   \n",
       "4           -0.031841         -0.012266     -0.043992      0.000986   \n",
       "..                ...               ...           ...           ...   \n",
       "747         -0.005318         -0.013488     -0.043992      0.000986   \n",
       "748         -0.017500         -0.005353     -0.043992      0.000986   \n",
       "749         -0.017698         -0.005206     -0.043992      0.000986   \n",
       "750         -0.023203         -0.007817     -0.043992      0.000986   \n",
       "751         -0.021495         -0.007095     -0.043992      0.000986   \n",
       "\n",
       "     country_PC1  country_PC2  content_rating_PC1  content_rating_PC2  \n",
       "0      -0.224117    -0.022061            0.148904            1.009111  \n",
       "1      -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "2       0.704948     0.473141           -0.647047           -0.158164  \n",
       "3      -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "4      -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "..           ...          ...                 ...                 ...  \n",
       "747    -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "748    -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "749     1.113117    -0.480086            0.093643            0.222252  \n",
       "750    -0.224117    -0.022061            0.097988            0.245086  \n",
       "751    -0.224117    -0.022061           -0.647047           -0.158164  \n",
       "\n",
       "[752 rows x 34 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
       "       'actor_3_facebook_likes', 'actor_1_facebook_likes', 'gross',\n",
       "       'num_voted_users', 'cast_total_facebook_likes', 'facenumber_in_poster',\n",
       "       'num_user_for_reviews', 'title_year', 'actor_2_facebook_likes',\n",
       "       'movie_facebook_likes', 'average_degree_centrality',\n",
       "       'title_embedding_PC1', 'title_embedding_PC2', 'genres_PC1',\n",
       "       'genres_PC2', 'plot_keywords_PC1', 'plot_keywords_PC2',\n",
       "       'director_name_PC1', 'director_name_PC2', 'actor_1_name_PC1',\n",
       "       'actor_1_name_PC2', 'actor_2_name_PC1', 'actor_2_name_PC2',\n",
       "       'actor_3_name_PC1', 'actor_3_name_PC2', 'language_PC1', 'language_PC2',\n",
       "       'country_PC1', 'country_PC2', 'content_rating_PC1',\n",
       "       'content_rating_PC2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = X_train.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16819334, -1.69245592, -0.25111333, ..., -0.10215625,\n",
       "         0.15918878,  0.5524476 ],\n",
       "       [ 0.71259343, -0.59691369, -0.26047711, ...,  2.08719009,\n",
       "        -1.02608494, -0.36488128],\n",
       "       [ 0.5476237 ,  0.31603816, -0.18222263, ..., -0.10215625,\n",
       "        -1.02608494, -0.36488128],\n",
       "       ...,\n",
       "       [ 0.41564792,  0.36168575, -0.10229605, ..., -0.10215625,\n",
       "        -1.02608494, -0.36488128],\n",
       "       [-0.46694011, -0.68820888, -0.26047711, ...,  3.08054829,\n",
       "         0.24018953,  2.29048112],\n",
       "       [-1.02783718,  0.22474297, -0.12704319, ...,  1.48282979,\n",
       "         1.21748826, -0.60460542]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.14331598,  0.36168575, -0.25579522, ..., -0.10215625,\n",
       "         0.24018953,  2.29048112],\n",
       "       [ 1.43021174,  1.41158038, -0.26047711, ..., -0.10215625,\n",
       "        -1.02608494, -0.36488128],\n",
       "       [-0.72264318, -0.68820888, -0.23071365, ...,  2.08719009,\n",
       "        -1.02608494, -0.36488128],\n",
       "       ...,\n",
       "       [-0.91235837,  0.31603816, -0.21599914, ..., -2.12713304,\n",
       "         0.15227622,  0.50050279],\n",
       "       [-0.66490378, -1.73810351, -0.26047711, ..., -0.10215625,\n",
       "         0.15918878,  0.5524476 ],\n",
       "       [-1.07732809, -1.05338962, -0.25913943, ..., -0.10215625,\n",
       "        -1.02608494, -0.36488128]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.2300266311584554\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "cross_val_predict_gnb = cross_val_predict(gnb, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_gnb) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_gnb}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_GNB_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6155126498002663\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "cross_val_predict_KNN = cross_val_predict(KNN, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_KNN) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred_KNN = KNN.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_KNN}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_KNN5_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.7230359520639148\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=888,n_jobs=-1)\n",
    "\n",
    "cross_val_predict_rf = cross_val_predict(rf_regressor, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_rf) == y_train.values)/len(y_train.values)) \n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "y_pred_rf = np.round(y_pred_rf) ## avoid some predictions not being integer \n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_rf}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_rf_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_voted_users</td>\n",
       "      <td>0.330611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gross</td>\n",
       "      <td>0.060634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.053451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_year</td>\n",
       "      <td>0.045186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_user_for_reviews</td>\n",
       "      <td>0.039010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>language_PC1</td>\n",
       "      <td>0.033647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>genres_PC2</td>\n",
       "      <td>0.032953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>genres_PC1</td>\n",
       "      <td>0.029415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actor_3_facebook_likes</td>\n",
       "      <td>0.026691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>title_embedding_PC2</td>\n",
       "      <td>0.021777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_critic_for_reviews</td>\n",
       "      <td>0.021374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>director_facebook_likes</td>\n",
       "      <td>0.020563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cast_total_facebook_likes</td>\n",
       "      <td>0.019773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plot_keywords_PC1</td>\n",
       "      <td>0.018855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>movie_facebook_likes</td>\n",
       "      <td>0.018621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>actor_2_facebook_likes</td>\n",
       "      <td>0.017979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>title_embedding_PC1</td>\n",
       "      <td>0.017624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>plot_keywords_PC2</td>\n",
       "      <td>0.015692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>actor_2_name_PC1</td>\n",
       "      <td>0.015340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>actor_3_name_PC2</td>\n",
       "      <td>0.014928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>actor_3_name_PC1</td>\n",
       "      <td>0.014540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>actor_2_name_PC2</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>director_name_PC2</td>\n",
       "      <td>0.014399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>director_name_PC1</td>\n",
       "      <td>0.013785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>average_degree_centrality</td>\n",
       "      <td>0.013408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>actor_1_name_PC2</td>\n",
       "      <td>0.012975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor_1_facebook_likes</td>\n",
       "      <td>0.012589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>actor_1_name_PC1</td>\n",
       "      <td>0.011331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>content_rating_PC1</td>\n",
       "      <td>0.010813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facenumber_in_poster</td>\n",
       "      <td>0.007321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>content_rating_PC2</td>\n",
       "      <td>0.007220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>country_PC1</td>\n",
       "      <td>0.005605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>country_PC2</td>\n",
       "      <td>0.004884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>language_PC2</td>\n",
       "      <td>0.002527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Features  importance\n",
       "6             num_voted_users    0.330611\n",
       "5                       gross    0.060634\n",
       "1                    duration    0.053451\n",
       "10                 title_year    0.045186\n",
       "9        num_user_for_reviews    0.039010\n",
       "28               language_PC1    0.033647\n",
       "17                 genres_PC2    0.032953\n",
       "16                 genres_PC1    0.029415\n",
       "3      actor_3_facebook_likes    0.026691\n",
       "15        title_embedding_PC2    0.021777\n",
       "0      num_critic_for_reviews    0.021374\n",
       "2     director_facebook_likes    0.020563\n",
       "7   cast_total_facebook_likes    0.019773\n",
       "18          plot_keywords_PC1    0.018855\n",
       "12       movie_facebook_likes    0.018621\n",
       "11     actor_2_facebook_likes    0.017979\n",
       "14        title_embedding_PC1    0.017624\n",
       "19          plot_keywords_PC2    0.015692\n",
       "24           actor_2_name_PC1    0.015340\n",
       "27           actor_3_name_PC2    0.014928\n",
       "26           actor_3_name_PC1    0.014540\n",
       "25           actor_2_name_PC2    0.014480\n",
       "21          director_name_PC2    0.014399\n",
       "20          director_name_PC1    0.013785\n",
       "13  average_degree_centrality    0.013408\n",
       "23           actor_1_name_PC2    0.012975\n",
       "4      actor_1_facebook_likes    0.012589\n",
       "22           actor_1_name_PC1    0.011331\n",
       "32         content_rating_PC1    0.010813\n",
       "8        facenumber_in_poster    0.007321\n",
       "33         content_rating_PC2    0.007220\n",
       "30                country_PC1    0.005605\n",
       "31                country_PC2    0.004884\n",
       "29               language_PC2    0.002527"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance = pd.DataFrame({'Features': columns,\n",
    "        'importance': rf_regressor.feature_importances_})\n",
    "df_importance.sort_values(by='importance', ascending=False, inplace=True)\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6827596899224806\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=666)\n",
    "\n",
    "accuracy = []\n",
    "# Iterate over K folds\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # Split data into training and test sets\n",
    "    #all_fold_indices.append(test_index) \n",
    "    X_train_temp, X_test_temp = X_train[train_index], X_train[test_index]\n",
    "    y_train_temp, y_test_temp = y_train.values[train_index], y_train.values[test_index]\n",
    "    y_train_categorical_temp = to_categorical(y_train_temp)\n",
    "    \n",
    "    ## set the model\n",
    "    \n",
    "    np.random.seed(888)\n",
    "    tf.random.set_seed(888)\n",
    "    random.seed(888)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],))) # input layer\n",
    "    model.add(Dense(512, activation='relu')) # hiden layer with 512 neurons\n",
    "    model.add(Dropout(0.2)) # drop out some neurons avoiding overfitting\n",
    "    model.add(Dense(1, activation='relu')) # pseudo regression-like output layer\n",
    "    model.add(Dense(5, activation='softmax'))  # output layer with 5 neurons for 5 classes using softmax activation\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_temp, y_train_categorical_temp, epochs=50, verbose=0)\n",
    "\n",
    "    # Generate predictions on the \"test set\"\n",
    "    predictions = np.argmax(model.predict(X_test_temp, verbose=0),axis=1)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy + [sum(predictions == y_test_temp)/len(y_test_temp)]\n",
    "    \n",
    "print('cross-val acc:',np.mean(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6293 - loss: 1.3582\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.6791 - loss: 1.1138\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.6869 - loss: 1.0339\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6874 - loss: 0.9807\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.6867 - loss: 0.9359\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.6999 - loss: 0.8985\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7040 - loss: 0.8790\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7056 - loss: 0.8532\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7100 - loss: 0.8393\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7038 - loss: 0.8274\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7188 - loss: 0.8147\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7272 - loss: 0.7946\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7350 - loss: 0.7925\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7381 - loss: 0.7782\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7278 - loss: 0.7772\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7382 - loss: 0.7620\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7373 - loss: 0.7569\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7428 - loss: 0.7498\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7449 - loss: 0.7409\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7457 - loss: 0.7326\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7522 - loss: 0.7216\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7490 - loss: 0.7252\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7594 - loss: 0.7056\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7547 - loss: 0.7012\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7476 - loss: 0.7114\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7658 - loss: 0.6872\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7603 - loss: 0.6873\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7681 - loss: 0.6893\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7614 - loss: 0.6736\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.7720 - loss: 0.6790\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7651 - loss: 0.6720\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7756 - loss: 0.6633\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7699 - loss: 0.6661\n",
      "Epoch 34/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7706 - loss: 0.6610\n",
      "Epoch 35/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7730 - loss: 0.6575\n",
      "Epoch 36/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7811 - loss: 0.6451\n",
      "Epoch 37/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7834 - loss: 0.6446\n",
      "Epoch 38/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7848 - loss: 0.6358\n",
      "Epoch 39/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7866 - loss: 0.6341\n",
      "Epoch 40/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7856 - loss: 0.6292\n",
      "Epoch 41/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7878 - loss: 0.6244\n",
      "Epoch 42/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7845 - loss: 0.6178\n",
      "Epoch 43/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7820 - loss: 0.6264\n",
      "Epoch 44/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7871 - loss: 0.6175\n",
      "Epoch 45/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7989 - loss: 0.6124\n",
      "Epoch 46/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7998 - loss: 0.6036\n",
      "Epoch 47/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7963 - loss: 0.6023\n",
      "Epoch 48/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7991 - loss: 0.6034\n",
      "Epoch 49/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7880 - loss: 0.6066\n",
      "Epoch 50/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7941 - loss: 0.6010\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train.values)\n",
    "np.random.seed(888)\n",
    "tf.random.set_seed(888)\n",
    "random.seed(888)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, epochs=50)\n",
    "#model_nn = model\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_nn}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_NN_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Round 4, feature selection based on MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "np.random.seed(888)\n",
    "random.seed(888)\n",
    "\n",
    "mi_scores = mutual_info_regression(X_train, y_train)  # For regression tasks\n",
    "\n",
    "# Create a DataFrame to store feature names and their MI scores\n",
    "mi_scores_df = pd.DataFrame({'Feature': columns, 'MI Score': mi_scores})\n",
    "mi_scores_df.sort_values(by='MI Score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>MI Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_voted_users</td>\n",
       "      <td>0.174967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>movie_facebook_likes</td>\n",
       "      <td>0.093768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_user_for_reviews</td>\n",
       "      <td>0.088804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.081324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_critic_for_reviews</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>director_name_PC2</td>\n",
       "      <td>0.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>director_facebook_likes</td>\n",
       "      <td>0.064057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>director_name_PC1</td>\n",
       "      <td>0.050020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cast_total_facebook_likes</td>\n",
       "      <td>0.045413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>genres_PC1</td>\n",
       "      <td>0.043558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor_1_facebook_likes</td>\n",
       "      <td>0.043430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>actor_1_name_PC1</td>\n",
       "      <td>0.043203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>actor_2_facebook_likes</td>\n",
       "      <td>0.042135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>content_rating_PC2</td>\n",
       "      <td>0.040550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>actor_1_name_PC2</td>\n",
       "      <td>0.040022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>content_rating_PC1</td>\n",
       "      <td>0.037001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>genres_PC2</td>\n",
       "      <td>0.035863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>actor_2_name_PC1</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>average_degree_centrality</td>\n",
       "      <td>0.031392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>country_PC2</td>\n",
       "      <td>0.028535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>actor_3_name_PC2</td>\n",
       "      <td>0.023699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gross</td>\n",
       "      <td>0.022576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>language_PC1</td>\n",
       "      <td>0.021719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actor_3_facebook_likes</td>\n",
       "      <td>0.019499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>plot_keywords_PC2</td>\n",
       "      <td>0.018623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>actor_2_name_PC2</td>\n",
       "      <td>0.013336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>actor_3_name_PC1</td>\n",
       "      <td>0.012786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>country_PC1</td>\n",
       "      <td>0.011545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_year</td>\n",
       "      <td>0.011224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>title_embedding_PC1</td>\n",
       "      <td>0.008791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>language_PC2</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>title_embedding_PC2</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facenumber_in_poster</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plot_keywords_PC1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  MI Score\n",
       "6             num_voted_users  0.174967\n",
       "12       movie_facebook_likes  0.093768\n",
       "9        num_user_for_reviews  0.088804\n",
       "1                    duration  0.081324\n",
       "0      num_critic_for_reviews  0.067453\n",
       "21          director_name_PC2  0.066400\n",
       "2     director_facebook_likes  0.064057\n",
       "20          director_name_PC1  0.050020\n",
       "7   cast_total_facebook_likes  0.045413\n",
       "16                 genres_PC1  0.043558\n",
       "4      actor_1_facebook_likes  0.043430\n",
       "22           actor_1_name_PC1  0.043203\n",
       "11     actor_2_facebook_likes  0.042135\n",
       "33         content_rating_PC2  0.040550\n",
       "23           actor_1_name_PC2  0.040022\n",
       "32         content_rating_PC1  0.037001\n",
       "17                 genres_PC2  0.035863\n",
       "24           actor_2_name_PC1  0.033561\n",
       "13  average_degree_centrality  0.031392\n",
       "31                country_PC2  0.028535\n",
       "27           actor_3_name_PC2  0.023699\n",
       "5                       gross  0.022576\n",
       "28               language_PC1  0.021719\n",
       "3      actor_3_facebook_likes  0.019499\n",
       "19          plot_keywords_PC2  0.018623\n",
       "25           actor_2_name_PC2  0.013336\n",
       "26           actor_3_name_PC1  0.012786\n",
       "30                country_PC1  0.011545\n",
       "10                 title_year  0.011224\n",
       "14        title_embedding_PC1  0.008791\n",
       "29               language_PC2  0.007500\n",
       "15        title_embedding_PC2  0.005386\n",
       "8        facenumber_in_poster  0.000000\n",
       "18          plot_keywords_PC1  0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6               num_voted_users\n",
      "12         movie_facebook_likes\n",
      "9          num_user_for_reviews\n",
      "1                      duration\n",
      "0        num_critic_for_reviews\n",
      "21            director_name_PC2\n",
      "2       director_facebook_likes\n",
      "20            director_name_PC1\n",
      "7     cast_total_facebook_likes\n",
      "16                   genres_PC1\n",
      "4        actor_1_facebook_likes\n",
      "22             actor_1_name_PC1\n",
      "11       actor_2_facebook_likes\n",
      "33           content_rating_PC2\n",
      "23             actor_1_name_PC2\n",
      "32           content_rating_PC1\n",
      "17                   genres_PC2\n",
      "24             actor_2_name_PC1\n",
      "13    average_degree_centrality\n",
      "31                  country_PC2\n",
      "Name: Feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train_copy2 = X_train.copy() ## backup of unselected scaled training set including text features\n",
    "X_test_copy2 = X_test.copy() ## backup of unselected scaled test set including text features\n",
    "X_train = X_train[:,mi_scores_df.index[0:20]]\n",
    "X_test = X_test[:,mi_scores_df.index[0:20]]\n",
    "print(mi_scores_df['Feature'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3004, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(752, 20)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.2796271637816245\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "## perform cross validation\n",
    "cross_val_predict_gnb = cross_val_predict(gnb, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_gnb) == y_train.values)/len(y_train.values))\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_gnb}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_GNB_text_select_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6324900133155792\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "cross_val_predict_KNN = cross_val_predict(KNN, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_KNN) == y_train.values)/len(y_train.values))\n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred_KNN = KNN.predict(X_test)\n",
    "\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_KNN}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_KNN5_text_select_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.7010652463382158\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=888,n_jobs=-1)\n",
    "\n",
    "cross_val_predict_rf = cross_val_predict(rf_regressor, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_rf) == y_train.values)/len(y_train.values))\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "y_pred_rf = np.round(y_pred_rf) ## avoid some predictions not being integer \n",
    "\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_rf}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_rf_text_select_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.66678073089701\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=666)\n",
    "\n",
    "accuracy = []\n",
    "# Iterate over K folds\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # Split data into training and test sets\n",
    "    #all_fold_indices.append(test_index) \n",
    "    X_train_temp, X_test_temp = X_train[train_index], X_train[test_index]\n",
    "    y_train_temp, y_test_temp = y_train.values[train_index], y_train.values[test_index]\n",
    "    y_train_categorical_temp = to_categorical(y_train_temp)\n",
    "    \n",
    "    ## set the model\n",
    "    \n",
    "    np.random.seed(888)\n",
    "    tf.random.set_seed(888)\n",
    "    random.seed(888)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],))) # input layer\n",
    "    model.add(Dense(512, activation='relu')) # hiden layer with 512 neurons\n",
    "    model.add(Dropout(0.2)) # drop out some neurons avoiding overfitting\n",
    "    model.add(Dense(1, activation='relu')) # pseudo regression-like output layer\n",
    "    model.add(Dense(5, activation='softmax'))  # output layer with 5 neurons for 5 classes using softmax activation\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_temp, y_train_categorical_temp, epochs=50, verbose=0)\n",
    "\n",
    "    # Generate predictions on the \"test set\"\n",
    "    predictions = np.argmax(model.predict(X_test_temp, verbose=0),axis=1)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy + [sum(predictions == y_test_temp)/len(y_test_temp)]\n",
    "    \n",
    "print('cross-val acc:',np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6243 - loss: 1.3739\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.6563 - loss: 1.1551\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.6573 - loss: 1.0744\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.6618 - loss: 1.0159\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6614 - loss: 0.9752\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.6608 - loss: 0.9419\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6660 - loss: 0.9175\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.6712 - loss: 0.8972\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.6747 - loss: 0.8830\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.6739 - loss: 0.8758\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6785 - loss: 0.8655\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.6840 - loss: 0.8580\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6823 - loss: 0.8482\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6817 - loss: 0.8458\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6884 - loss: 0.8391\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6852 - loss: 0.8344\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6861 - loss: 0.8233\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.6883 - loss: 0.8238\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6901 - loss: 0.8181\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.6926 - loss: 0.8195\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7004 - loss: 0.8093\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.6939 - loss: 0.8084\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.6987 - loss: 0.8006\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7036 - loss: 0.7960\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.7004 - loss: 0.8013\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7034 - loss: 0.7923\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.6974 - loss: 0.7929\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7063 - loss: 0.7840\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7056 - loss: 0.7829\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7047 - loss: 0.7778\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7004 - loss: 0.7826\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7060 - loss: 0.7782\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.7109 - loss: 0.7742\n",
      "Epoch 34/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7097 - loss: 0.7762\n",
      "Epoch 35/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7066 - loss: 0.7701\n",
      "Epoch 36/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7096 - loss: 0.7670\n",
      "Epoch 37/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7104 - loss: 0.7642\n",
      "Epoch 38/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.7111 - loss: 0.7598\n",
      "Epoch 39/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.7157 - loss: 0.7585\n",
      "Epoch 40/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7226 - loss: 0.7548\n",
      "Epoch 41/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7191 - loss: 0.7511\n",
      "Epoch 42/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7135 - loss: 0.7518\n",
      "Epoch 43/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7248 - loss: 0.7475\n",
      "Epoch 44/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7108 - loss: 0.7529\n",
      "Epoch 45/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.7226 - loss: 0.7453\n",
      "Epoch 46/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7200 - loss: 0.7383\n",
      "Epoch 47/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.7239 - loss: 0.7443\n",
      "Epoch 48/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7238 - loss: 0.7370\n",
      "Epoch 49/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7177 - loss: 0.7406\n",
      "Epoch 50/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7199 - loss: 0.7427\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train.values)\n",
    "np.random.seed(888)\n",
    "tf.random.set_seed(888)\n",
    "random.seed(888)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, epochs=50)\n",
    "#model_nn = model\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_nn}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_NN_text_select_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Round 5, feature selection based on RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6               num_voted_users\n",
       "5                         gross\n",
       "1                      duration\n",
       "10                   title_year\n",
       "9          num_user_for_reviews\n",
       "28                 language_PC1\n",
       "17                   genres_PC2\n",
       "16                   genres_PC1\n",
       "3        actor_3_facebook_likes\n",
       "15          title_embedding_PC2\n",
       "0        num_critic_for_reviews\n",
       "2       director_facebook_likes\n",
       "7     cast_total_facebook_likes\n",
       "18            plot_keywords_PC1\n",
       "12         movie_facebook_likes\n",
       "11       actor_2_facebook_likes\n",
       "14          title_embedding_PC1\n",
       "19            plot_keywords_PC2\n",
       "24             actor_2_name_PC1\n",
       "27             actor_3_name_PC2\n",
       "Name: Features, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### renew the data with new features from selection method of RF\n",
    "X_train = X_train_copy2.copy()[:,df_importance.index[0:20]]\n",
    "X_test = X_test_copy2.copy()[:,df_importance.index[0:20]]\n",
    "df_importance['Features'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3004, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(752, 20)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.2496671105193076\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "## perform cross validation\n",
    "cross_val_predict_gnb = cross_val_predict(gnb, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_gnb) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_gnb}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_GNB_text_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.631491344873502\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "cross_val_predict_KNN = cross_val_predict(KNN, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_KNN) == y_train.values)/len(y_train.values)) \n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred_KNN = KNN.predict(X_test)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_KNN}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_KNN5_text_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.7250332889480693\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=888,n_jobs=-1)\n",
    "\n",
    "cross_val_predict_rf = cross_val_predict(rf_regressor, X_train, y_train, cv=10)\n",
    "print('cross-val acc:', sum(np.round(cross_val_predict_rf) == y_train.values)/len(y_train.values)) \n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "y_pred_rf = np.round(y_pred_rf) ## avoid some predictions not being integer \n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_rf}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_rf_text_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_voted_users</td>\n",
       "      <td>0.339882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gross</td>\n",
       "      <td>0.073225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.059659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title_year</td>\n",
       "      <td>0.053283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_user_for_reviews</td>\n",
       "      <td>0.047008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>genres_PC2</td>\n",
       "      <td>0.040915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>genres_PC1</td>\n",
       "      <td>0.037109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language_PC1</td>\n",
       "      <td>0.036236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>actor_3_facebook_likes</td>\n",
       "      <td>0.032698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cast_total_facebook_likes</td>\n",
       "      <td>0.030414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>title_embedding_PC2</td>\n",
       "      <td>0.028673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_critic_for_reviews</td>\n",
       "      <td>0.028122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>director_facebook_likes</td>\n",
       "      <td>0.027830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>plot_keywords_PC1</td>\n",
       "      <td>0.025860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>actor_3_name_PC2</td>\n",
       "      <td>0.024970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>actor_2_facebook_likes</td>\n",
       "      <td>0.023684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>title_embedding_PC1</td>\n",
       "      <td>0.023396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>actor_2_name_PC1</td>\n",
       "      <td>0.023114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>movie_facebook_likes</td>\n",
       "      <td>0.022674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>plot_keywords_PC2</td>\n",
       "      <td>0.021250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Features  importance\n",
       "0             num_voted_users    0.339882\n",
       "1                       gross    0.073225\n",
       "2                    duration    0.059659\n",
       "3                  title_year    0.053283\n",
       "4        num_user_for_reviews    0.047008\n",
       "6                  genres_PC2    0.040915\n",
       "7                  genres_PC1    0.037109\n",
       "5                language_PC1    0.036236\n",
       "8      actor_3_facebook_likes    0.032698\n",
       "12  cast_total_facebook_likes    0.030414\n",
       "9         title_embedding_PC2    0.028673\n",
       "10     num_critic_for_reviews    0.028122\n",
       "11    director_facebook_likes    0.027830\n",
       "13          plot_keywords_PC1    0.025860\n",
       "19           actor_3_name_PC2    0.024970\n",
       "15     actor_2_facebook_likes    0.023684\n",
       "16        title_embedding_PC1    0.023396\n",
       "18           actor_2_name_PC1    0.023114\n",
       "14       movie_facebook_likes    0.022674\n",
       "17          plot_keywords_PC2    0.021250"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance1 = pd.DataFrame({'Features': columns[df_importance.index[0:20]],\n",
    "        'importance': rf_regressor.feature_importances_})\n",
    "df_importance1.sort_values(by='importance', ascending=False, inplace=True)\n",
    "df_importance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val acc: 0.6900675526024364\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=666)\n",
    "\n",
    "accuracy = []\n",
    "# Iterate over K folds\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # Split data into training and test sets\n",
    "    #all_fold_indices.append(test_index) \n",
    "    X_train_temp, X_test_temp = X_train[train_index], X_train[test_index]\n",
    "    y_train_temp, y_test_temp = y_train.values[train_index], y_train.values[test_index]\n",
    "    y_train_categorical_temp = to_categorical(y_train_temp)\n",
    "    \n",
    "    ## set the model\n",
    "    \n",
    "    np.random.seed(888)\n",
    "    tf.random.set_seed(888)\n",
    "    random.seed(888)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],))) # input layer\n",
    "    model.add(Dense(512, activation='relu')) # hiden layer with 512 neurons\n",
    "    model.add(Dropout(0.2)) # drop out some neurons avoiding overfitting\n",
    "    model.add(Dense(1, activation='relu')) # pseudo regression-like output layer\n",
    "    model.add(Dense(5, activation='softmax'))  # output layer with 5 neurons for 5 classes using softmax activation\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_temp, y_train_categorical_temp, epochs=50, verbose=0)\n",
    "\n",
    "    # Generate predictions on the \"test set\"\n",
    "    predictions = np.argmax(model.predict(X_test_temp, verbose=0),axis=1)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy + [sum(predictions == y_test_temp)/len(y_test_temp)]\n",
    "    \n",
    "print('cross-val acc:',np.mean(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6283 - loss: 1.3636\n",
      "Epoch 2/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6698 - loss: 1.1309\n",
      "Epoch 3/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.6782 - loss: 1.0531\n",
      "Epoch 4/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.6801 - loss: 0.9953\n",
      "Epoch 5/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.6848 - loss: 0.9564\n",
      "Epoch 6/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.6923 - loss: 0.9208\n",
      "Epoch 7/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.6976 - loss: 0.8970\n",
      "Epoch 8/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.6980 - loss: 0.8815\n",
      "Epoch 9/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.6989 - loss: 0.8667\n",
      "Epoch 10/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6975 - loss: 0.8583\n",
      "Epoch 11/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7057 - loss: 0.8463\n",
      "Epoch 12/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7121 - loss: 0.8367\n",
      "Epoch 13/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7075 - loss: 0.8306\n",
      "Epoch 14/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7094 - loss: 0.8229\n",
      "Epoch 15/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7112 - loss: 0.8166\n",
      "Epoch 16/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7154 - loss: 0.8072\n",
      "Epoch 17/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7140 - loss: 0.8035\n",
      "Epoch 18/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7163 - loss: 0.8005\n",
      "Epoch 19/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7162 - loss: 0.7952\n",
      "Epoch 20/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7230 - loss: 0.7882\n",
      "Epoch 21/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7245 - loss: 0.7858\n",
      "Epoch 22/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7136 - loss: 0.7803\n",
      "Epoch 23/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7181 - loss: 0.7748\n",
      "Epoch 24/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.7281 - loss: 0.7705\n",
      "Epoch 25/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7287 - loss: 0.7639\n",
      "Epoch 26/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7311 - loss: 0.7570\n",
      "Epoch 27/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7332 - loss: 0.7549\n",
      "Epoch 28/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7345 - loss: 0.7504\n",
      "Epoch 29/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7257 - loss: 0.7509\n",
      "Epoch 30/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7332 - loss: 0.7513\n",
      "Epoch 31/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7331 - loss: 0.7437\n",
      "Epoch 32/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7332 - loss: 0.7360\n",
      "Epoch 33/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7360 - loss: 0.7351\n",
      "Epoch 34/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7405 - loss: 0.7368\n",
      "Epoch 35/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7409 - loss: 0.7299\n",
      "Epoch 36/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7465 - loss: 0.7226\n",
      "Epoch 37/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7423 - loss: 0.7228\n",
      "Epoch 38/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7404 - loss: 0.7225\n",
      "Epoch 39/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7415 - loss: 0.7173\n",
      "Epoch 40/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.7511 - loss: 0.7101\n",
      "Epoch 41/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7414 - loss: 0.7090\n",
      "Epoch 42/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7405 - loss: 0.7151\n",
      "Epoch 43/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7462 - loss: 0.7055\n",
      "Epoch 44/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7508 - loss: 0.7046\n",
      "Epoch 45/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7442 - loss: 0.6994\n",
      "Epoch 46/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7475 - loss: 0.6999\n",
      "Epoch 47/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.7477 - loss: 0.6936\n",
      "Epoch 48/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7537 - loss: 0.6905\n",
      "Epoch 49/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7469 - loss: 0.6969\n",
      "Epoch 50/50\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7577 - loss: 0.6917\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train.values)\n",
    "np.random.seed(888)\n",
    "tf.random.set_seed(888)\n",
    "random.seed(888)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, epochs=50)\n",
    "#model_nn = model\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)\n",
    "data_temp = {'id': data_test['id'],\n",
    "        'imdb_score_binned': y_pred_nn}\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "df_temp.to_csv('output_NN_text_select.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
